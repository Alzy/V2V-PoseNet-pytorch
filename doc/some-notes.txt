## 实现时的一些差异，需要注意：
- 体素内的坐标点使用i,j,k表示； 作者使用x,y,z表示
- 


## 原则
1. 简化问题，逐步验证
2. 做测试，做好测试（例如可视化，测试驱动）


## 经验
1.
- 做好单元测试， 做好可视化测试， 测试要完整
  - 除了静态的，也需要动态测试，例如动态的不断epoch训练时，原始数据是否被更改了

- 检查各个层（包含loss层）的foward, backward的误差，例如跟numpy的结果做对比，例如用gradcheck工具等
  - 注意foward是否有偏差，只检查backward，并不能保证forward实现正确否（有其是没bug，但实现不对）
  - 注意有些过程会有精度的损失，尽量了解，以及避免损失精度

- 用1个以及多个样本去跟进下网络过程，训练过程。最好有预先的断言或测试（正确时满足的一些约束）

2.
- 检查训练的输入，输出数据对，包含原始的，增强后的，迭代过程中的，可以用一个样本简单看下

- 检查最终输入给网络的输入，输出数据是否是期望的形式，例如检查或可视化体素化后的输入，以及目标热力图

- 检查初始loss，以及思考和验证为什么是这样（后续也需要关注loss的变化，例如loss很快就不下降了，是什么问题）

- 简化，拆解和降低整个问题的难度。例如寻找问题合适的子问题（例如输入相似，但目标子问题可以更简单点），先去验证
网络是否能学习。例如先使用简单的网络去拟合很小的数据集

- 拟合少量的（单个或多个）样本，看看loss的变化。如果loss不能下降，那么应该是出现了什么问题。例如考虑
loss值较高，却不下降，那有可能是梯度消失问题。特别是多次实验发现loss都停留在某个值附件，例如3e-4，那么可以
考虑为什么是这个值。从本项目的网络来讲，loss不下降，稳定在某个高值时，检查样本的输出发现大部分为0，造成了这样
的loss值。由于目标热力图也是大部分为0，可能会误认为没有太大问题。但是实际具体情况是，网络的最后一层（本身是卷积）
错误的实现成了ReLU，当ReLU输出为0时，梯度也容易为0，我们可以继续查验（或可视化）当前的梯度去调试。

- 拟合单个样本，loss下降的比较慢，或者更本下降不到比较合理的值是什么问题？
这个有很多原因，例如网络的问题（比如输出层不好，梯度不流通，难以拟合和学习）。如果本身网络没有多少问题，那么
也可能是代码实现的问题。例如本项目拟合一个样本时，cudnn+float的loss很难降下去。我们可以考虑是否是float的
精度问题，于是简化问题使用cudnn+double。然后loss降了下去。所以，这可能是cudnn实现某些层是有些问题，或者
我们的网络比较复杂（例如比较深，梯度反向传播时，逐渐消散减小）。我们可以继续去做些实验，例如不使用cudnn的实现，
而是直接使用cuda+float，结果也能下去。
[todo] (1) cpu + float如何? 如果可以，那么是cudnn+float在某些层的问题，或者网络梯度容易消散
[todo] (2) 为什么cudnn+float不行，如果是某些层，那是哪些层
[todo] (3) 就算是cudnn+float在某些层不行，能否通过resnet的形式，畅通梯度？ 网络梯度容易消散么？

- 实验过程中，可以禁止随机性
  包括使用/对比cpu/cuda/cudnn，都是为了简化问题规模，或者相互验证，缩小问题的范围，找到问题的来源

- 权重初始化很重要，注意网络默认初始值，以及对于本问题是否合理

- 本身库有没有bug，例如更新库，或者查看github上的issue或release的doc


##问题：
1. 本以为对dataset的数据在外部所给的transform中进行修改值时，会影响到原始值，而导致下一个epoch取值时会产生
变化，但并没有。
[todo] 查看下是为什么


## 其他
1. 输入输出数据对，包括原始的，增强的，迭代中的
2. output, target以及之间的loss
3. 模型差异，权重初始化
4. 优化器
5. 配置差异, cudnn, 随机性，double/float（当前的模型发现，double比float训练更稳定，更容易学习数据，虽然模型跑的更慢）
6. pytorch本身的bug，例如MSELoss? 检查它们的forward和backward.


需要补充的
1. 3维体数据可视化
2. python test, 熟悉测试原则和技巧


技巧：
1. 缩小数据进行拟合
2. 简化网络进行拟合


实验发现
1. v2v原始model, double比float训练容易，float基本不成功
1.1 v2v原始model，cudnn=False，禁用cudnn能训练， torch.backends.cudnn.enabled = False
1.2 是因为cudnn batchnorm? micosoft-pytorch-pose github 提到 cudnn batchnorm有些问题

2. 一个小的v2v model更容易拟合？ 再测试下
3. 拟合少量数据时, rmsprop, adam比sgd更简单些，adam训练的更快更好?


--12.2--
1. [closed]查找为什么cudnn不行（但cudnn+double可以），可能是某些层的实现精度有问题？或者是这个网络比较复杂，且
某些层有问题，导致梯度消失或爆炸？ cpu+float呢?
- 应该是batchnorm+cudnn的问题

2. [todo]dataset为什么没有被scale影响

3. [todo]目前能拟合单个样本，尝试逐步增进到原始问题的难度
- 与作者的实现做对比验证

4. [closed]cuda比cudnn多了几倍的现存消耗？
- 考虑是否能安装新版本的的cuda, cudnn以及pytorch解决上述问题
- 关闭掉cudnn for batchnorm能够正常工作
- [todo] pytorch上提一个issue

5. val_epoch()时，除了返回loss(MSELoss()), 增加计算acc，例如只在volume坐标系内，计算OKS, PKS等
- 因为mse loss变化较小，需要转换到关键点上（求max())

